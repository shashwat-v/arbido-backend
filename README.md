# âš¡ Arbido â€” Pairs Trading Dashboard (Backend)

### ğŸ§  High-Performance Python Engine for Statistical Arbitrage

The **Arbido Backend** powers the Pairs Trading Dashboard with **real-time data ingestion**, **statistical computations**, and **asynchronous background processing** â€” designed for speed, scalability, and precision.

---

## ğŸš€ Overview

Arbido's backend is a **modular Python-based system** that handles:

- ğŸ“ˆ Fetching price data from APIs (e.g., Fyers)
- âš™ï¸ Processing pairs for cointegration, correlation, and spread analysis
- â± Running background Celery tasks for heavy computations
- ğŸ§® Serving metrics & insights to the frontend dashboard
- ğŸª¶ Dockerized microservice architecture for smooth deployment

Built using **FastAPI**, **Celery**, **Redis**, and **Python**, Arbido Backend ensures **low latency**, **fault tolerance**, and **scalability**.

---

## ğŸ§© Tech Stack

| Component           | Technology                              |
| ------------------- | --------------------------------------- |
| ğŸ§  Core Language    | Python 3.11+                            |
| âš™ï¸ Web Framework    | FastAPI                                 |
| ğŸ§® Task Queue       | Celery                                  |
| ğŸ—„ï¸ Message Broker   | Redis                                   |
| ğŸ“Š Data Handling    | Pandas, NumPy                           |
| ğŸ” API Client       | Fyers API                               |
| ğŸ³ Containerization | Docker + Docker Compose                 |
| ğŸ§¾ Logging          | Python `logging` module                 |
| âš¡ Environment      | `.env` file for secrets and credentials |

---

## ğŸ—‚ï¸ Project Structure

```
arbido-backend/
â”‚
â”œâ”€â”€ data/                      # Local CSVs / market data
â”‚   â”œâ”€â”€ NSE_RELIANCE-EQ_30min.csv
â”‚   â”œâ”€â”€ NSE_TCS-EQ_30min.csv
â”‚   â””â”€â”€ pairs_NSE:RELIANCE-EQ_NSE:TCS-EQ.csv
â”‚
â”œâ”€â”€ logs/                      # Application and Celery logs
â”‚   â”œâ”€â”€ celery.log
â”‚   â”œâ”€â”€ fyersApi.log
â”‚   â””â”€â”€ fyersRequests.log
â”‚
â”œâ”€â”€ services/                  # Core backend service modules
â”‚   â”œâ”€â”€ celery_worker.py
â”‚   â”œâ”€â”€ fyers_auth.py
â”‚   â”œâ”€â”€ fyers_client.py
â”‚   â”œâ”€â”€ data_fetcher.py
â”‚   â”œâ”€â”€ pairs_metrics_engine.py
â”‚   â””â”€â”€ tasks.py
â”‚
â”œâ”€â”€ main.py                    # Application entry point
â”œâ”€â”€ models.py                  # Pydantic or ORM models
â”œâ”€â”€ requirements.txt           # Dependencies list
â”œâ”€â”€ docker-compose.yml         # Multi-service orchestration
â”œâ”€â”€ Dockerfile                 # Backend image definition
â”œâ”€â”€ .env                       # Environment variables
â””â”€â”€ .gitignore                 # Ignored files and folders
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/shashwat-v/arbido-backend.git
cd arbido-backend
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create a `.env` File

Example:

```bash
FYERS_CLIENT_ID=your_client_id
FYERS_SECRET_KEY=your_secret_key
FYERS_ACCESS_TOKEN=your_access_token
REDIS_URL=redis://localhost:6379/0
```

---

## ğŸ§µ Running the Backend

### ğŸ§© Option 1 â€” Run with Python (Development Mode)

#### Start FastAPI Server:

```bash
python main.py
```

#### Start Celery Worker:

```bash
celery -A services.celery_worker.celery_app worker --loglevel=info
```

---

### ğŸ³ Option 2 â€” Run with Docker (Recommended)

Start all services (API + Celery + Redis) with one command:

```bash
docker-compose up --build
```

âœ… This will automatically start:

- FastAPI backend
- Redis broker
- Celery worker

---

## ğŸ“¡ API Endpoints (Example)

| Endpoint         | Method | Description                                              |
| ---------------- | ------ | -------------------------------------------------------- |
| `/pairs-data`    | `POST` | Fetches price data for a given symbol or pair            |
| `/pairs-metrics` | `GET`  | Returns statistical metrics (z-score, beta, correlation) |
| `/health`        | `GET`  | Health check endpoint                                    |

Example request:

```bash
POST /pairs-data
{
  "ticker_1": "NSE:RELIANCE-EQ",
  "ticker_2": "NSE:TCS-EQ"
}
```

---

## ğŸ§  Core Services

### ğŸ”¹ `data_fetcher.py`

Fetches OHLCV data from Fyers API or CSVs for selected instruments.

### ğŸ”¹ `pairs_metrics_engine.py`

Computes key metrics like:

- Correlation
- Cointegration
- Mean reversion
- Z-score
- Beta ratio

### ğŸ”¹ `celery_worker.py`

Runs Celery worker and handles background processing for heavy tasks.

### ğŸ”¹ `fyers_auth.py` & `fyers_client.py`

Manages Fyers API authentication, tokens, and data requests.

---

## ğŸ§° Logging

All logs are stored under the `/logs` directory:

```
logs/
â”œâ”€â”€ celery.log
â”œâ”€â”€ fyersApi.log
â””â”€â”€ fyersRequests.log
```

You can modify logging levels inside `main.py` or `celery_worker.py`.

---

## ğŸ§¾ Environment Variables Reference

| Variable             | Description                               |
| -------------------- | ----------------------------------------- |
| `FYERS_CLIENT_ID`    | Your Fyers API Client ID                  |
| `FYERS_SECRET_KEY`   | Your Fyers Secret Key                     |
| `FYERS_ACCESS_TOKEN` | Access Token for authentication           |
| `REDIS_URL`          | Redis connection string                   |
| `API_PORT`           | (Optional) Custom port for FastAPI server |

---

## ğŸ§® Example Workflow

1. User triggers data fetch from the frontend.
2. FastAPI receives the request and enqueues a Celery task.
3. Celery worker fetches data via `fyers_client.py`.
4. Data is processed by `pairs_metrics_engine.py`.
5. Results are logged and returned as metrics JSON to the frontend.

---

## ğŸ§± Docker Deployment Notes

- Default container names: `arbido_api`, `arbido_celery`, `arbido_redis`
- Logs are mapped to host volume `/logs`
- Environment variables are loaded from `.env`
- To rebuild images after code changes:
  ```bash
  docker-compose up --build
  ```

---

## ğŸ§¾ License

This project is licensed under the **MIT License**.

---

## ğŸ‘¤ Author

**Shashwat Vishwakarma**  
Aspiring Quant Trader | Developer | Finance Enthusiast  
ğŸ“§ [shashwatv.dev@gmail.com](mailto:shashwatv.dev@gmail.com)  
ğŸŒ [LinkedIn](https://linkedin.com/in/shashwat-v)

---

## ğŸ’¡ Notes

- For development, Celery warnings like `"You're running the worker with superuser privileges"` are harmless in Docker containers â€” just avoid root in production.
- Use small candle intervals (5â€“15m) for faster backtesting.
